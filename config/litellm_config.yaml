model_list:
  # Anthropic Claude (requires ANTHROPIC_API_KEY env var)
  - model_name: default
    litellm_params:
      model: claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY

  - model_name: claude-haiku-4
    litellm_params:
      model: claude-haiku-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY

  # Optional: OpenAI (requires OPENAI_API_KEY env var)
  - model_name: gpt-4o
    litellm_params:
      model: gpt-4o
      api_key: os.environ/OPENAI_API_KEY

  # Local Ollama models (via host.docker.internal)
  # Use ollama_chat/ prefix for proper chat API support
  - model_name: deepseek-r1
    litellm_params:
      model: ollama_chat/deepseek-r1:latest
      api_base: http://host.docker.internal:11434

  - model_name: gemma3
    litellm_params:
      model: ollama_chat/gemma3:4b
      api_base: http://host.docker.internal:11434

  - model_name: llama3
    litellm_params:
      model: ollama_chat/llama3:latest
      api_base: http://host.docker.internal:11434
